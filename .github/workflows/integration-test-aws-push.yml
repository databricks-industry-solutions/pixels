name: AWS integration test push

on:
 workflow_dispatch:
 push:
    branches:
      - main

jobs:
 run-databricks-notebook:
   runs-on: html_publisher
   steps:
     - name: Checkout repo
       uses: actions/checkout@v2
     - name: Run a databricks notebook
       uses: databricks/run-notebook@v0
       with:
         local-notebook-path: RUNME.py
         git-commit: ${{ github.sha }}
         databricks-host: https://e2-demo-west.cloud.databricks.com
         databricks-token: ${{ secrets.DEPLOYMENT_TARGET_TOKEN_AWS }}
         new-cluster-json: >
          {
            "num_workers": 1,
            "spark_version": "13.3.x-scala2.12",
            "node_type_id": "i3.xlarge",
            "aws_attributes": {
              "availability": "ON_DEMAND"
            },
            "custom_tags": {
              "ResourceClass": "SingleNode"
            },
            "policy_id": "E0631F5C0D0006EA"
          }
         notebook-params-json: >
           {
            "run_job": "True"
           }
         access-control-list-json: >
           [
             {
               "group_name": "users",
               "permission_level": "CAN_VIEW"
             }
           ]
