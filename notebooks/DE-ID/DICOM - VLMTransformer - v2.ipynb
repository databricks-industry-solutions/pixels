{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50bb7869-cb72-47cc-b0a4-8ffbd193891c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Detect DICOM Image PHI and Redact PHI\n",
    "- Recommended cluster: 16.4 LTS ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4f3528b-1338-4383-9ced-dcba4c64169b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup `pixels` package (if you haven't done so)\n",
    "1. [Create a git folder](https://docs.databricks.com/aws/en/repos/git-operations-with-repos) cloning the [pixels](https://github.com/databricks-industry-solutions/pixels) package\n",
    "2. Then run the [`config/setup.py`]($./config/setup) script in the repo folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "245b51ab-6685-46a8-b26b-0d5e2a11f235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./config/setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "066aebc1-258f-4921-84c6-14377c82a970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "961f4b9e-c572-4af0-afa4-422848b209c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_dir = \"/Volumes/hls_radiology/tcia/redacted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "717f4ca4-412e-4638-bb01-38f3541e6f34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load input dataframe\n",
    "`VLMPhiExtractor` requires that input be must be ONE of the following:\n",
    "1. a .dcm file path (e.g. `/Volumes/<catalog>/<schema>/2.1.656.0.2.8048482.9.537.165816238/1-1.dcm`)\n",
    "2. image file path (e.g. `/Volumes/<catalog>/<schema>/2.1.656.0.2.8048482.9.537.165816238/1-1.jpg`)\n",
    "3. image encoded as a base64 string required by VLM (e.g. `/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwc...`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cec69e44-1df8-4d44-9fb0-8e6dc795c2e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### A table of DICOM paths already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d9f065c-981d-422a-bdbb-654203167f21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "  spark.table(\"hls_radiology.tcia.midi_b_val_subset\")\n",
    "  .drop('jpg_base64str', 'jpg_base64str_masked')\n",
    ")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91106984-d302-40ad-af43-d258214a0886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bulk run: `VLMTransformer().transform(df)`\n",
    "Returns a df with a new column `response` (specify in `outputCol`) returned by the VLM specified in `endpoint`\n",
    "\n",
    "`VLMTransformer` wraps around `VLMPhiExtractor` for spark dataframe transformations.<br>\n",
    "It also allows 3 types of inputs (see earlier [cell](https://e2-demo-field-eng.cloud.databricks.com/editor/notebooks/372649807139118?o=1444828305810485#command/3070146489819417)):\n",
    "1. `input_type=\"dicom\"` for .dcm file path\n",
    "2. `input_type=\"image\"` for image file path\n",
    "3. `input_type=\"base64\"`for image encoded as a base64 string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e4ed1ec-6dd8-4967-b409-f8e8d8da321a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Run VLM transformer for PHI detection\n",
    "- 1 partition: 1.89s/image (132 sec/70 images)\n",
    "- 8 partitions: 0.8s/image (56 sec/70 images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "157ee631-8f1a-40a3-9807-3ab2b91e5ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dbx.pixels.dicom.dicom_vlm_phi_detector import VLMTransformer\n",
    "\n",
    "# For .dcm path input (inputCol=\"path\", input_type=\"dicom\")\n",
    "vlm_transformer = VLMTransformer(endpoint=\"databricks-claude-3-7-sonnet\", input_type=\"dicom\")\n",
    "\n",
    "df = df.repartition(8) # for parallelism\n",
    "out_df = vlm_transformer.transform(df)\n",
    "display(out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b77f7fe-6cfb-4964-a118-99c36b9182c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extract PHI entities and evaluate against ground truth (`has_phi`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e57091f9-43fe-4488-93c4-ff4debe09bb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col, when, size\n",
    "\n",
    "extracted_df = (out_df\n",
    "    .withColumn(\"entities\", col(\"response.content\"))\n",
    "    .withColumn(\"phi_detected\", when(size(col(\"entities\"))>1, True).otherwise(False))\n",
    "    #.drop(\"jpg_base64str\", \"jpg_base64str_masked\")\n",
    ")\n",
    "display(extracted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9317c0-dc0d-4693-95f0-296f38ae30db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract selected columns and convert to pandas for subsequent sklearn metrics computation\n",
    "extracted_pdf = extracted_df.select(\"has_phi\", \"phi_detected\").toPandas()\n",
    "display(extracted_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d993325-6908-473e-abb0-12c3d41ca79f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "precision = precision_score(extracted_pdf.has_phi, extracted_pdf.phi_detected)\n",
    "recall = recall_score(extracted_pdf.has_phi, extracted_pdf.phi_detected)\n",
    "f1 = f1_score(extracted_pdf.has_phi, extracted_pdf.phi_detected)\n",
    "accuracy = accuracy_score(extracted_pdf.has_phi, extracted_pdf.phi_detected)\n",
    "\n",
    "precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "610fdc6e-b296-4a20-8430-2796a1dd1d9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bulk redaction with Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b7d0d9-cd08-499c-ada6-02a514c7e0b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from dbx.pixels.dicom.dicom_utils import array_to_image\n",
    "from dbx.pixels.dicom.dicom_easyocr_redactor import ocr_dcm\n",
    "#from typing import BinaryIO\n",
    "\n",
    "@pandas_udf(\"map<string, string>\")\n",
    "def ocr2redactarr_udf(paths: pd.Series) -> pd.Series:\n",
    "    def ocr2redactarr(path: str) -> str:\n",
    "        # Find text bounding boxes and apply fill mask\n",
    "        redacted_array = ocr_dcm(path, display=False, gpu=True)\n",
    "        # Save redacted images as jpg in output_dir\n",
    "        suffix = \"_\".join(path.split(\"/\")[-2:])\n",
    "        output_path=f'{output_dir}/{suffix.replace(\".dcm\", \".jpg\")}'\n",
    "        array_to_image(redacted_array,\n",
    "                              output_path=output_path,\n",
    "                              return_type=None)\n",
    "        return {\"source\": path, \"redacted\": output_path}\n",
    "    return paths.apply(ocr2redactarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93c1fbbf-43de-4574-a166-9102333cabf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Run OCR Redactor\n",
    "- 1 partition: 65.7s/image (591 sec/9 images)\n",
    "- 8 partitions: 43.4s/image (391 sec/9 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0f58785-d823-45b7-bcfd-1f38d7771ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "redact_df = extracted_df.where(extracted_df.phi_detected==True)\n",
    "redact_df = redact_df.repartition(8)\n",
    "\n",
    "# Bulk redaction with path as input\n",
    "display(redact_df.select(ocr2redactarr_udf(col(\"path\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c425a0d-fcf1-4195-bb40-79565e4d9fc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "View the files in the [output_dir](https://e2-demo-field-eng.cloud.databricks.com/explore/data/volumes/hls_radiology/tcia/redacted)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DICOM - VLMTransformer - v2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
