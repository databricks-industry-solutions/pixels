{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Row-Level Security: Unity Catalog → Lakebase Sync\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "\n",
        "1. **Set up row-level access control in Unity Catalog** using dynamic views and `is_account_group_member()`.\n",
        "2. **Mirror those rules into Lakebase** (PostgreSQL) so the DICOMweb cache respects the same restrictions.\n",
        "3. **Sync user → group mappings** from the Databricks SCIM API into Lakebase.\n",
        "4. **Run the sync job** that tags each cached row with `allowed_groups` so PostgreSQL RLS policies can enforce access.\n",
        "\n",
        "---\n",
        "\n",
        "### Why is this needed?\n",
        "\n",
        "The Pixels DICOMweb application uses a **3-tier caching hierarchy**:\n",
        "\n",
        "| Tier | Backend | Lifetime |\n",
        "|------|---------|----------|\n",
        "| 1 | In-memory (`BOTCache`, `InstancePathCache`) | Process lifetime |\n",
        "| 2 | Lakebase (PostgreSQL) | Persistent across restarts |\n",
        "| 3 | Unity Catalog SQL Warehouse | Source of truth |\n",
        "\n",
        "When Unity Catalog **row filters** restrict which DICOM files a user may see, the caches\n",
        "at Tiers 1 and 2 could bypass those filters — returning cached rows the user should not\n",
        "have access to.\n",
        "\n",
        "The solution:\n",
        "- **Tier 1 (in-memory)** — cache keys include a hash of the user's groups, so different\n",
        "  users never share entries.\n",
        "- **Tier 2 (Lakebase)** — each row carries an `allowed_groups` array; PostgreSQL RLS\n",
        "  policies filter rows based on the user's groups set via `SET LOCAL app.user_groups = ...`.\n",
        "\n",
        "> **Prerequisites**: A Databricks workspace with Unity Catalog enabled, a Lakebase\n",
        "> instance provisioned, and the `dbx-pixels` package installed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Configuration\n",
        "\n",
        "Edit the variables below to match your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Unity Catalog coordinates ──────────────────────────────────────────\n",
        "CATALOG   = \"main\"\n",
        "SCHEMA    = \"pixels_solacc\"\n",
        "VOLUME    = \"pixels_volume\"\n",
        "TABLE     = \"object_catalog\"       # the pixels table with DICOM metadata\n",
        "\n",
        "# Fully qualified table name (used throughout)\n",
        "UC_TABLE  = f\"{CATALOG}.{SCHEMA}.{TABLE}\"\n",
        "\n",
        "# ── Group names ─────────────────────────────────────────────────────────\n",
        "# These must match your Databricks Account groups.\n",
        "GROUP_PHI            = \"pixels_phi\"            # full access to all DICOM data\n",
        "GROUP_DEIDENTIFIED   = \"pixels_deidentified\"   # access only to de-identified data\n",
        "\n",
        "# ── Lakebase ────────────────────────────────────────────────────────────\n",
        "LAKEBASE_INSTANCE    = \"pixels-lakebase\"       # name of the Lakebase instance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Unity Catalog — Grant base permissions\n",
        "\n",
        "Before creating row filters, every group needs `USE CATALOG`, `USE SCHEMA`, `READ VOLUME`,\n",
        "and `SELECT` on the objects they will access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for group in [GROUP_PHI, GROUP_DEIDENTIFIED]:\n",
        "    spark.sql(f\"GRANT USE CATALOG ON CATALOG {CATALOG} TO `{group}`;\")\n",
        "    spark.sql(f\"GRANT USE SCHEMA ON SCHEMA {CATALOG}.{SCHEMA} TO `{group}`;\")\n",
        "    spark.sql(f\"GRANT READ VOLUME ON VOLUME {CATALOG}.{SCHEMA}.{VOLUME} TO `{group}`;\")\n",
        "    spark.sql(f\"GRANT SELECT ON TABLE {UC_TABLE} TO `{group}`;\")\n",
        "    print(f\"✓ Base permissions granted to {group}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Unity Catalog — Create a row-filtered dynamic view\n",
        "\n",
        "The dynamic view uses `is_account_group_member()` to apply different `WHERE` clauses\n",
        "depending on the caller's group membership:\n",
        "\n",
        "| Group | Access |\n",
        "|-------|--------|\n",
        "| `pixels_phi` | **All** rows (full PHI access) |\n",
        "| `pixels_deidentified` | Only rows where `DeIdentificationMethod` (DICOM tag `00120063`) is **not null** |\n",
        "| Everyone else | **No** rows |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROW_FILTERED_VIEW = \"dicom_row_filtered\"\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.{ROW_FILTERED_VIEW} AS\n",
        "SELECT * FROM {UC_TABLE}\n",
        "WHERE\n",
        "  CASE\n",
        "    WHEN is_account_group_member('{GROUP_PHI}')          THEN TRUE\n",
        "    WHEN is_account_group_member('{GROUP_DEIDENTIFIED}') THEN meta:['00120063'].Value[0] IS NOT NULL\n",
        "    ELSE FALSE\n",
        "  END\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(f\"ALTER VIEW {CATALOG}.{SCHEMA}.{ROW_FILTERED_VIEW} SET TAGS ('phi', 'pixels_anonym')\")\n",
        "\n",
        "# Grant SELECT on the view so each group can query it\n",
        "for group in [GROUP_PHI, GROUP_DEIDENTIFIED]:\n",
        "    spark.sql(f\"GRANT SELECT ON TABLE {CATALOG}.{SCHEMA}.{ROW_FILTERED_VIEW} TO `{group}`;\")\n",
        "\n",
        "print(f\"✓ Row-filtered view created: {CATALOG}.{SCHEMA}.{ROW_FILTERED_VIEW}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick validation\n",
        "\n",
        "Query the view to see which rows the *current* user can access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = spark.sql(f\"SELECT * EXCEPT (thumbnail) FROM {CATALOG}.{SCHEMA}.{ROW_FILTERED_VIEW}\")\n",
        "print(f\"Rows visible to current user: {df.count()}\")\n",
        "df.display()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. (Optional) Column masking via dynamic view\n",
        "\n",
        "In addition to row filtering, you can mask sensitive columns for non-PHI groups.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLUMN_MASKED_VIEW = \"dicom_column_masked\"\n",
        "\n",
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.{COLUMN_MASKED_VIEW} AS\n",
        "SELECT * EXCEPT (meta),\n",
        "  CASE\n",
        "    WHEN IS_ACCOUNT_GROUP_MEMBER('{GROUP_PHI}') THEN meta\n",
        "    ELSE '[REDACTED]'\n",
        "  END AS meta\n",
        "FROM {UC_TABLE}\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(f\"ALTER VIEW {CATALOG}.{SCHEMA}.{COLUMN_MASKED_VIEW} SET TAGS ('phi', 'pixels_anonym')\")\n",
        "\n",
        "for group in [GROUP_PHI, GROUP_DEIDENTIFIED]:\n",
        "    spark.sql(f\"GRANT SELECT ON TABLE {CATALOG}.{SCHEMA}.{COLUMN_MASKED_VIEW} TO `{group}`;\")\n",
        "\n",
        "print(f\"✓ Column-masked view created: {CATALOG}.{SCHEMA}.{COLUMN_MASKED_VIEW}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Lakebase — Initialize the RLS schema\n",
        "\n",
        "Connect to Lakebase and apply the RLS DDL. This creates:\n",
        "\n",
        "| Object | Purpose |\n",
        "|--------|---------|\n",
        "| `pixels.access_rules` | Admin-managed table mirroring UC row filter logic |\n",
        "| `pixels.user_groups` | User email → group mappings (synced from SCIM) |\n",
        "| `allowed_groups TEXT[]` column | Added to `instance_paths` and `dicom_frames` |\n",
        "| RLS policies | `SELECT` restricted by group overlap; `INSERT`/`UPDATE` unrestricted |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from dbx.pixels.lakebase import LakebaseUtils\n",
        "\n",
        "# Connect to (or create) the Lakebase instance.\n",
        "# Passing uc_table_name aligns the Lakebase database + schema to UC:\n",
        "# catalog.schema.table → database = \"catalog\", schema = \"schema\".\n",
        "lb = LakebaseUtils(\n",
        "    instance_name=LAKEBASE_INSTANCE,\n",
        "    create_instance=True,\n",
        "    uc_table_name=UC_TABLE,\n",
        ")\n",
        "print(f\"✓ Connected to Lakebase instance: {lb.instance_name}, database: {lb.database}, schema: {lb.schema}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dbx.pixels.lakebase as _lb_mod\n",
        "\n",
        "_sql_dir = Path(_lb_mod.__file__).parent / \"resources\" / \"sql\" / \"lakebase\"\n",
        "\n",
        "# Apply all schema files in order.\n",
        "# SQL files use {schema_name} placeholders that are filled with the UC-aligned schema.\n",
        "sql_files = [\n",
        "    \"CREATE_LAKEBASE_SCHEMA.sql\",\n",
        "    \"CREATE_LAKEBASE_DICOM_FRAMES.sql\",\n",
        "    \"CREATE_LAKEBASE_RLS.sql\",               # ← RLS tables, columns & policies\n",
        "]\n",
        "\n",
        "for sql_file in sql_files:\n",
        "    with open(_sql_dir / sql_file) as fh:\n",
        "        lb.execute_query(fh.read().format(schema_name=lb.schema))\n",
        "    print(f\"  ✓ Applied {sql_file}\")\n",
        "\n",
        "print(f\"\\n✓ Lakebase schema '{lb.schema}' initialised with RLS support\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Sync user → group mappings from Databricks SCIM\n",
        "\n",
        "This pulls every user and their group memberships from the workspace SCIM API and\n",
        "upserts them into `pixels.user_groups`. The DICOMweb app reads this table at request\n",
        "time to resolve the caller's groups.\n",
        "\n",
        "> **Tip**: Schedule this cell as a periodic job (e.g. daily) to keep mappings current.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "synced_count = lb.sync_user_groups_from_databricks()\n",
        "print(f\"✓ Synced {synced_count} (user, group) pairs from SCIM to Lakebase\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify: show the first 20 user-group mappings\n",
        "from psycopg2 import sql as psql\n",
        "rows = lb.execute_and_fetch_query(\n",
        "    psql.SQL(\"SELECT user_email, group_name, synced_at FROM {} ORDER BY user_email LIMIT 20\").format(\n",
        "        psql.Identifier(lb.schema, \"user_groups\")\n",
        "    )\n",
        ")\n",
        "print(f\"{'Email':<45} {'Group':<30} {'Synced At'}\")\n",
        "print(\"-\" * 95)\n",
        "for email, group, synced_at in rows:\n",
        "    print(f\"{email:<45} {group:<30} {synced_at}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Define access rules in Lakebase\n",
        "\n",
        "Access rules mirror the UC row filter logic. Each rule maps a `(uc_table, group)` pair to an access pattern:\n",
        "\n",
        "| `access_type` | Meaning |\n",
        "|---------------|---------|\n",
        "| `full` | The group may see **all** rows cached from this UC table |\n",
        "| `conditional` | The group may only see rows matching `uc_filter_sql` |\n",
        "\n",
        "The `uc_filter_sql` column must contain a valid Unity Catalog `WHERE` clause. The sync job (Step 7) will execute it against the UC table to discover which SOP Instance UIDs match.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rule 1: pixels_phi → full access to all rows\n",
        "lb.upsert_access_rule(\n",
        "    uc_table_name=UC_TABLE,\n",
        "    group_name=GROUP_PHI,\n",
        "    access_type=\"full\",\n",
        "    description=\"Full access to all DICOM data (PHI group)\",\n",
        ")\n",
        "\n",
        "# Rule 2: pixels_deidentified → only de-identified data\n",
        "lb.upsert_access_rule(\n",
        "    uc_table_name=UC_TABLE,\n",
        "    group_name=GROUP_DEIDENTIFIED,\n",
        "    access_type=\"conditional\",\n",
        "    uc_filter_sql=\"meta:['00120063'].Value[0] IS NOT NULL\",\n",
        "    description=\"Access only to de-identified DICOM data\",\n",
        ")\n",
        "\n",
        "print(\"✓ Access rules upserted\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify: list all rules for this table\n",
        "rules = lb.get_access_rules(UC_TABLE)\n",
        "print(f\"Access rules for {UC_TABLE}:\\n\")\n",
        "for r in rules:\n",
        "    print(f\"  Group:       {r['group_name']}\")\n",
        "    print(f\"  Access type: {r['access_type']}\")\n",
        "    print(f\"  Filter SQL:  {r['uc_filter_sql'] or '(none — full access)'}\")\n",
        "    print(f\"  Description: {r['description']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Sync UC row filters → Lakebase `allowed_groups`\n",
        "\n",
        "This is the **core sync step**. For each access rule:\n",
        "\n",
        "- **`full`** rules → the group is added to `allowed_groups` on *every* cached row for the table.\n",
        "- **`conditional`** rules → the sync job queries the UC table with the `uc_filter_sql` to find matching SOP Instance UIDs, then adds the group only to *those* cached rows.\n",
        "\n",
        "The sync is **additive** (groups are appended, never removed). To do a clean re-sync, call `reset_allowed_groups()` first.\n",
        "\n",
        "> **Note**: The SQL client must authenticate as a **service principal** with full `SELECT` on the UC table (not subject to the row filter). This ensures the conditional queries can see all rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from databricks.sdk.core import Config\n",
        "from dbx.pixels.resources.dicom_web.utils.sql_client import DatabricksSQLClient\n",
        "\n",
        "cfg = Config()\n",
        "sql_client = DatabricksSQLClient(\n",
        "    host=cfg.host,\n",
        "    warehouse_id=os.environ[\"DATABRICKS_WAREHOUSE_ID\"],\n",
        ")\n",
        "\n",
        "print(f\"✓ SQL client connected to warehouse {os.environ['DATABRICKS_WAREHOUSE_ID']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: reset allowed_groups before a full re-sync\n",
        "# Uncomment the next line for a clean slate (all cached rows become unrestricted\n",
        "# until the sync completes).\n",
        "\n",
        "# lb.reset_allowed_groups(UC_TABLE)\n",
        "# print(f\"✓ Reset allowed_groups for {UC_TABLE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "updated = lb.sync_uc_row_filters(UC_TABLE, sql_client)\n",
        "print(f\"\\n✓ Sync complete — {updated} Lakebase row(s) updated\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Verify RLS enforcement in Lakebase\n",
        "\n",
        "Let's simulate what different users would see when querying Lakebase directly. We use `SET LOCAL app.user_groups` to set the session context — this is exactly what the DICOMweb application does before each Lakebase query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_visible_rows(lb_utils, table_name: str, user_groups: list[str]) -> int:\n",
        "    \"\"\"Count how many rows are visible under the given user groups.\"\"\"\n",
        "    from psycopg2 import sql as psql\n",
        "    rows = lb_utils.execute_and_fetch_query(\n",
        "        psql.SQL(\"SELECT COUNT(*) FROM {} WHERE uc_table_name = %s\").format(\n",
        "            psql.Identifier(lb_utils.schema, table_name)\n",
        "        ),\n",
        "        params=(UC_TABLE,),\n",
        "        user_groups=user_groups,\n",
        "    )\n",
        "    return rows[0][0] if rows else 0\n",
        "\n",
        "\n",
        "# Rows visible to PHI group (should be ALL)\n",
        "phi_ip = count_visible_rows(lb, \"instance_paths\", [GROUP_PHI])\n",
        "phi_df = count_visible_rows(lb, \"dicom_frames\", [GROUP_PHI])\n",
        "\n",
        "# Rows visible to de-identified group (should be a subset)\n",
        "deid_ip = count_visible_rows(lb, \"instance_paths\", [GROUP_DEIDENTIFIED])\n",
        "deid_df = count_visible_rows(lb, \"dicom_frames\", [GROUP_DEIDENTIFIED])\n",
        "\n",
        "# Rows visible with no groups (should be only unrestricted/legacy rows)\n",
        "anon_ip = count_visible_rows(lb, \"instance_paths\", [])\n",
        "anon_df = count_visible_rows(lb, \"dicom_frames\", [])\n",
        "\n",
        "print(f\"{'Group':<30} {'instance_paths':>16} {'dicom_frames':>16}\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"{GROUP_PHI:<30} {phi_ip:>16,} {phi_df:>16,}\")\n",
        "print(f\"{GROUP_DEIDENTIFIED:<30} {deid_ip:>16,} {deid_df:>16,}\")\n",
        "print(f\"{'(no groups)':<30} {anon_ip:>16,} {anon_df:>16,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Enable RLS on the DICOMweb App\n",
        "\n",
        "To activate RLS enforcement at runtime, set these environment variables on your Databricks App deployment:\n",
        "\n",
        "```bash\n",
        "# Enable on-behalf-of (OBO) user authentication\n",
        "export DICOMWEB_USE_USER_AUTH=true\n",
        "\n",
        "# Enable Lakebase Row-Level Security\n",
        "export LAKEBASE_RLS_ENABLED=true\n",
        "\n",
        "# Initialize Lakebase schema on startup (creates RLS tables + policies)\n",
        "export LAKEBASE_INIT_DB=true\n",
        "\n",
        "# Lakebase instance name\n",
        "export LAKEBASE_INSTANCE_NAME=pixels-lakebase\n",
        "```\n",
        "\n",
        "Once active, the application will:\n",
        "\n",
        "1. Resolve the user's email from the `X-Forwarded-Email` header.\n",
        "2. Look up their groups from `pixels.user_groups` in Lakebase.\n",
        "3. Set `SET LOCAL app.user_groups = '...'` on every Lakebase query.\n",
        "4. Include a groups hash in the in-memory cache key.\n",
        "\n",
        "### Security matrix\n",
        "\n",
        "| Cache Tier | Protection Mechanism |\n",
        "|------------|---------------------|\n",
        "| Tier 1 — In-memory | Cache keys scoped by groups hash |\n",
        "| Tier 2 — Lakebase | PostgreSQL RLS with `allowed_groups && user_groups` |\n",
        "| Tier 3 — UC SQL Warehouse | Native UC row filters (OBO token) |\n",
        "| File reads (Volumes API) | OBO token → UC ACLs at storage layer |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10. Ongoing maintenance\n",
        "\n",
        "Schedule the following as periodic jobs to keep the RLS mappings current:\n",
        "\n",
        "```python\n",
        "from dbx.pixels.lakebase import LakebaseUtils\n",
        "from dbx.pixels.resources.dicom_web.utils.sql_client import DatabricksSQLClient\n",
        "\n",
        "lb = LakebaseUtils(instance_name=\"pixels-lakebase\")\n",
        "\n",
        "# 1. Re-sync user → group mappings (new hires, role changes)\n",
        "lb.sync_user_groups_from_databricks()\n",
        "\n",
        "# 2. Re-sync UC row filters → Lakebase allowed_groups\n",
        "#    (after adding new access rules or when cached data changes)\n",
        "sql_client = DatabricksSQLClient(host=\"...\", warehouse_id=\"...\")\n",
        "lb.reset_allowed_groups(\"main.pixels_solacc.object_catalog\")\n",
        "lb.sync_uc_row_filters(\"main.pixels_solacc.object_catalog\", sql_client)\n",
        "```\n",
        "\n",
        "### Adding a new access group\n",
        "\n",
        "1. Create the group in Databricks Account Console.\n",
        "2. Add the group to Unity Catalog row filter logic (update the dynamic view).\n",
        "3. Add a matching access rule in Lakebase:\n",
        "\n",
        "```python\n",
        "lb.upsert_access_rule(\n",
        "    uc_table_name=\"main.pixels_solacc.object_catalog\",\n",
        "    group_name=\"new_group_name\",\n",
        "    access_type=\"conditional\",\n",
        "    uc_filter_sql=\"meta:['00120063'].Value[0] = 'Per DICOM PS 3.15 AnnexE'\",\n",
        "    description=\"Access to data de-identified with a specific method\",\n",
        ")\n",
        "```\n",
        "\n",
        "4. Re-run the sync:\n",
        "\n",
        "```python\n",
        "lb.sync_user_groups_from_databricks()\n",
        "lb.reset_allowed_groups(\"main.pixels_solacc.object_catalog\")\n",
        "lb.sync_uc_row_filters(\"main.pixels_solacc.object_catalog\", sql_client)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Define access rules in Lakebase\n",
        "\n",
        "Access rules mirror the UC row filter logic. Each rule maps a `(uc_table, group)` pair\n",
        "to an access pattern:\n",
        "\n",
        "| `access_type` | Meaning |\n",
        "|---------------|---------|\n",
        "| `full` | The group may see **all** rows cached from this UC table |\n",
        "| `conditional` | The group may only see rows matching `uc_filter_sql` |\n",
        "\n",
        "The `uc_filter_sql` column must contain a valid **Unity Catalog** `WHERE` clause.\n",
        "The sync job (Step 7) will execute it against the UC table to discover which\n",
        "SOP Instance UIDs match.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
