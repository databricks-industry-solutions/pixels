{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4251ff89-b74f-40f0-b5ac-4c3113168957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet numpy==1.26.4 pydicom==3.0.1 nvidia-nvimgcodec-cu12[all] highdicom nvidia-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "962b3b29-4b1e-4e05-9d4b-3a2c5bf605e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a040c8b3-a5a1-4d4e-832f-a4d59dc8d580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# sgc test 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aff0fa0a-d205-4cde-8795-3e7ab4f242c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2731dee1-d5a4-4362-b6aa-00176eb3ac61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ca7cca9-2d65-47d0-a15f-d1915e77ac42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "logger_format = '%(asctime)s [%(levelname)s] [%(name)s:%(lineno)d] %(message)s'\n",
    "# Check if a handler is already present (Jupyter usually adds one by default)\n",
    "if logger.handlers:\n",
    "    # Get the existing handler (usually the first one)\n",
    "    handler = logger.handlers[0]\n",
    "    # Set the level to INFO\n",
    "    handler.setLevel(logging.INFO)\n",
    "    # Define a simple formatter without color codes\n",
    "    formatter = logging.Formatter(logger_format)\n",
    "    handler.setFormatter(formatter)\n",
    "else:\n",
    "    # If no handler, configure basicConfig (less common in modern Jupyter)\n",
    "    logging.basicConfig(level=logging.INFO, format=logger_format)\n",
    "\n",
    "\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
    "\n",
    "# In your notebook\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7317f0b-4ebd-4f7c-b8e6-f4e0d6eed53b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "cfg = yaml.safe_load(open('config.yaml'))\n",
    "\n",
    "compression = \"nvImage_HTJ2K_progressive\"\n",
    "input_path = cfg.get(\"input_path\")\n",
    "output_path = cfg.get(\"output_path\").replace(\"{compression}\", f\"{compression}\")\n",
    "experiment_name = cfg.get(\"experiment_name\")\n",
    "\n",
    "table = \"main.pixels_solacc.object_catalog\"\n",
    "experiment_log_dir = \"/Volumes/douglas_moore/mlflow/experiments\"\n",
    "\n",
    "data_batch_size=1024\n",
    "gpu_max_batch_size = 1024\n",
    "folder_limit = 10000\n",
    "num_gpus = 1\n",
    "CODE_FOLDER = '/Workspace/Users/douglas.moore@databricks.com/pixels-jpeg2000/notebooks/transcoding'\n",
    "sys.path.append(CODE_FOLDER)\n",
    "\n",
    "#os.environ['PYNVIMGCODEC_VERBOSITY'] = '5'\n",
    "\n",
    "input_path, output_path\n",
    "\n",
    "#set GPU logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad33edd5-d453-4a35-83c7-4073d9a6f830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pull dir paths to compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a620cde3-2e08-46e3-b420-ba5e54a8c208",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col, split, size, slice\n",
    "from pyspark.sql.functions import col, split, size, slice, concat\n",
    "from pyspark.sql.functions import array_join\n",
    "\n",
    "#\n",
    "## Chunk up dirs\n",
    "#\n",
    "\n",
    "df = spark.read.table(\"hls_radiology.tcia.object_catalog\")\n",
    "df = df.where(\"meta:['00280100'].Value[0] is not null\") # remove dicom files not having required bitsAllocated\n",
    "df = df.where(\"not (meta:['00280002'].Value[0] = 3 and meta:['00280006'].Value[0] is null)\")\n",
    "df = df.withColumn('dirs', array_join(slice(split(col('path'), '/'), 1, size(split(col('path'), '/')) - 1), '/'))\n",
    "df = df.withColumn('dir', split(col('dirs'),':')[1])\n",
    "df = df.select('dir').distinct().orderBy('dir').limit(folder_limit)\n",
    "\n",
    "pdf = df.toPandas()\n",
    "chunks = np.array_split(pdf, num_gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1025e533-990c-419c-9879-fa79181e8554",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dicom_file_iterator import DICOMFileIterator\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import pprint\n",
    "from convert_htj2k_p3 import transcode_dicom_to_htj2k\n",
    "\n",
    "folders = pdf['dir'].to_list()\n",
    "dataset = DICOMFileIterator(root=input_path, target=output_path, folders=folders)\n",
    "dataloader = DataLoader(dataset, batch_size=data_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074d14c4-6902-4a8f-b647-c7d5736e8767",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "transcode_dicom_to_htj2k(\n",
    "    dataloader,\n",
    "    root_dir = input_path,\n",
    "    output_dir = output_path,\n",
    "    max_batch_size=gpu_max_batch_size\n",
    ")\n",
    "duration = time.time() - start\n",
    "print(f\"{duration :.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "944f3278-75d2-439a-ad25-b0f306e1d90d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh ls /Volumes/hls_radiology/tcia/htj2k_compressed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "198aefb7-c366-4e05-9f87-d96d0425b4e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "mkdir -p /Workspace/Users/douglas.moore@databricks.com/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe91db5a-559b-45c3-820c-74cdc4064d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import glob\n",
    "import pydicom\n",
    "\n",
    "print(experiment_name)\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment = mlflow.create_experiment(experiment_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce5e2ad4-6bb6-45a5-91e7-a3e79feb23dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "run_name = f\"compress_{compression}\"\n",
    "with mlflow.start_run( log_system_metrics=True) as run:\n",
    "\n",
    "    #init\n",
    "    import logging\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    # Initialization (per worker basis)\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    sys.path.append(CODE_FOLDER)\n",
    "    from convert_htj2k_p2 import transcode_dicom_to_htj2k\n",
    "    os.environ['PYNVIMGCODEC_VERBOSITY'] = '6'\n",
    "    \n",
    "    # Log artifacts (source DICOM, compressed DICOM, config)\n",
    "    mlflow.log_artifact(\"config.yaml\", artifact_path=\"config\")\n",
    "\n",
    "    # Check for a GPU\n",
    "    try:\n",
    "        import subprocess\n",
    "        gpu_info = subprocess.check_output(\"nvidia-smi -L\", shell=True).decode().strip()\n",
    "        mlflow.log_param(\"gpu_info\", gpu_info)\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        mlflow.log_param(\"gpu_info\", \"No GPU detected\")\n",
    "\n",
    "    # Log the full requirements.txt file of the current environment\n",
    "    with open(\"full_requirements.txt\", \"w\") as f:\n",
    "        subprocess.run([\"pip\", \"freeze\"], stdout=f)\n",
    "    mlflow.log_artifact(\"full_requirements.txt\")\n",
    "\n",
    "    # Optionally log code snapshot\n",
    "    #mlflow.log_artifact(\"notebook.py\", artifact_path=\"source_code\")\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"compression\", compression)\n",
    "    mlflow.log_param(\"input_path\", input_path)\n",
    "    mlflow.log_param(\"output_path\", output_path)\n",
    "    mlflow.log_param(\"encoder\", \"nvimgcodec\")\n",
    "#    mlflow.log_param(\"enc_params.jpeg2k_params.ht\", enc_params.jpeg2k_params.ht)\n",
    "#    mlflow.log_param(\"enc_params.jpeg2k_params.num_resolutions\", enc_params.jpeg2k_params.num_resolutions)\n",
    "\n",
    "\n",
    "    # run compression\n",
    "    from convert_htj2k_p2 import transcode_dicom_to_htj2k\n",
    "\n",
    "    start = time.time()\n",
    "    transcode_dicom_to_htj2k(\n",
    "        input_dir=input_path,\n",
    "        output_dir=output_path\n",
    "    )\n",
    "    duration = time.time() - start\n",
    "    print(f\"{duration :.2f}s\")\n",
    "    mlflow.log_metric(\"duration_seconds\", round(duration, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce550472-933f-4bb8-8102-701f3b51a81b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "numpy==1.26.4",
     "pydicom==3.0.1",
     "nvidia-nvimgcodec-cu12[all]",
     "highdicom",
     "nvidia-ml-py"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7573039815312346,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "sgc-test-3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
